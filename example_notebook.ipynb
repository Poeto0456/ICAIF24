{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from os import path as pt\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from src.evaluation.summary import full_evaluation\n",
    "from src.utils import set_seed, save_obj, load_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8937, 24, 3])\n",
      "torch.Size([8937, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/ref_log_return.pkl\", \"rb\") as f:\n",
    "    loaded_array = pickle.load(f)\n",
    "train_log_return = torch.tensor(loaded_array)\n",
    "print(train_log_return.shape)\n",
    "\n",
    "with open(\"./data/ref_price.pkl\", \"rb\") as f:\n",
    "    loaded_array = pickle.load(f)\n",
    "train_init_price = torch.tensor(loaded_array)\n",
    "print(train_init_price.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative models for time series generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration dict\n",
    "config_dir = 'configs/config.yaml'\n",
    "with open(config_dir, encoding='utf-8') as file:\n",
    "    config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "    \n",
    "set_seed(config.seed)\n",
    "\n",
    "if (config.device ==\n",
    "        \"cuda\" and torch.cuda.is_available()):\n",
    "    config.update({\"device\": \"cuda:0\"}, allow_val_change=True)\n",
    "else:\n",
    "    config.update({\"device\": \"cpu\"}, allow_val_change=True)\n",
    "    \n",
    "class XYDataset(TensorDataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.shape = X.shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the data into training and validation set for the offline evaluation of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7149, 24, 3]) torch.Size([7149, 1, 3]) torch.Size([1788, 24, 3]) torch.Size([1788, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "perm_idx = torch.randperm(train_log_return.shape[0])\n",
    "train_size = int(0.8*train_log_return.shape[0])\n",
    "\n",
    "cv_training_data = train_log_return[perm_idx[:train_size]].to(config.device).to(torch.float)\n",
    "cv_init_price = train_init_price[perm_idx[:train_size]].to(config.device).to(torch.float)\n",
    "cv_validation_data = train_log_return[perm_idx[train_size:]].to(config.device).to(torch.float)\n",
    "cv_val_init_price = train_init_price[perm_idx[train_size:]].to(config.device).to(torch.float)\n",
    "\n",
    "print(cv_training_data.shape, cv_init_price.shape, cv_validation_data.shape, cv_val_init_price.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3]) torch.Size([24, 3])\n",
      "torch.Size([256, 1, 3]) torch.Size([256, 24, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "training_set = TensorDataset(cv_init_price, cv_training_data)\n",
    "\n",
    "print(training_set[0][0].shape, training_set[0][1].shape)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    training_set,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for batch in train_dl:\n",
    "    print(batch[0].shape, batch[1].shape)\n",
    "    break\n",
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a generator and a discriminator for this task. Both the generator and discriminator takes as input the time series. Then we have the training algorithm TailGANTrainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from src.baselines.Diffusion import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim =  3 # 24 hours x 3 cryptocurrencies\n",
    "hidden_dim = 512\n",
    "timesteps = 100\n",
    "batch_size = config.batch_size\n",
    "epochs = 5\n",
    "set_seed(42)\n",
    "betas = linear_beta_schedule(timesteps)\n",
    "model = ScoreNetwork(input_dim=input_dim, hidden_dim=hidden_dim).to(device)\n",
    "trainer = DDPM(model, betas=betas, train_dl=train_dl, timesteps=timesteps)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 215.4932\n",
      "Epoch 2/5, Average Loss: 0.2517\n",
      "Epoch 3/5, Average Loss: 0.1616\n",
      "Epoch 4/5, Average Loss: 0.1468\n",
      "Epoch 5/5, Average Loss: 0.1365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(optimizer=optimizer, epochs=epochs)\n",
    "save_obj(trainer.model.state_dict(), './submission_bundle/model_dict.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1800, 24, 3])\n",
      "tensor([[[-1.6483e-03,  1.0965e-03,  9.9535e-04],\n",
      "         [-1.2715e-03,  1.0834e-03,  5.0533e-04],\n",
      "         [-1.3431e-03,  9.8036e-04,  5.3993e-04],\n",
      "         ...,\n",
      "         [ 6.3318e-03, -1.0101e-02,  8.0456e-03],\n",
      "         [-1.2682e-03,  1.1004e-03,  5.9748e-04],\n",
      "         [-2.4880e-03,  7.7853e-04, -5.7324e-04]],\n",
      "\n",
      "        [[-7.0275e-04,  1.3481e-03,  6.5233e-04],\n",
      "         [-1.2286e-03,  1.1093e-03,  4.7122e-04],\n",
      "         [-1.1500e-03,  1.0593e-03,  6.0745e-04],\n",
      "         ...,\n",
      "         [-9.3809e-04,  8.4386e-04,  7.6436e-04],\n",
      "         [-5.2958e-03,  7.2353e-03, -1.4559e-03],\n",
      "         [-1.3302e-03,  1.0365e-03,  6.6083e-04]],\n",
      "\n",
      "        [[-1.3468e-03,  8.5255e-04,  5.1631e-04],\n",
      "         [-1.3240e-03,  9.8264e-04,  4.8372e-04],\n",
      "         [-2.0458e-03,  1.1292e-04,  8.6764e-04],\n",
      "         ...,\n",
      "         [-1.5469e-03,  1.1453e-03,  8.0484e-04],\n",
      "         [ 7.3468e-03, -1.7595e-03, -1.5087e-03],\n",
      "         [-1.3707e-03,  8.3661e-04,  1.0118e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9020e-03,  1.3844e-03,  9.8259e-04],\n",
      "         [-1.7076e-03,  2.5983e-03,  2.5006e-03],\n",
      "         [-2.8276e-03, -8.3861e-03, -4.6227e-03],\n",
      "         ...,\n",
      "         [-1.0489e-03,  1.7984e-03,  4.1851e-05],\n",
      "         [-1.3834e-03,  1.0203e-03,  6.6645e-04],\n",
      "         [-2.3475e-03,  6.4285e-04, -3.1059e-04]],\n",
      "\n",
      "        [[-1.3528e-03,  8.4582e-04,  5.4269e-04],\n",
      "         [-2.5744e-03, -9.8141e-04, -2.5661e-03],\n",
      "         [-3.1296e-03,  1.1094e-03,  1.7118e-03],\n",
      "         ...,\n",
      "         [-4.7567e-03,  5.0455e-03,  1.8339e-03],\n",
      "         [ 9.8903e-05,  5.6236e-04, -1.9729e-03],\n",
      "         [-1.3552e-03,  9.4378e-04,  5.3265e-04]],\n",
      "\n",
      "        [[ 6.5509e-03,  3.2322e-03,  4.9024e-03],\n",
      "         [ 5.5757e-03,  7.0733e-03,  1.4127e-02],\n",
      "         [-1.1508e-03,  1.1197e-03,  3.9177e-04],\n",
      "         ...,\n",
      "         [-1.4761e-03,  1.2779e-03,  3.4146e-04],\n",
      "         [-1.2493e-03,  1.0069e-03,  5.9065e-04],\n",
      "         [ 1.2290e-03,  2.6681e-03, -1.8040e-03]]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = load_obj('./submission_bundle/model_dict.pkl')\n",
    "\n",
    "trainer.model.load_state_dict(state_dict)\n",
    "\n",
    "trainer.model.eval()\n",
    "\n",
    "eval_size = 1800\n",
    "\n",
    "with torch.no_grad():\n",
    "     generated_sample = trainer.sample(eval_size)\n",
    "\n",
    "print(generated_sample.shape)\n",
    "print(generated_sample)\n",
    "save_obj(generated_sample, './submission_bundle/fake_log_return.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the performance of our model by first generating the price process, apply the prespecified trading strategies and compare the resulting PnL process using the real and fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Metrics per Strategy:\n",
      "Strategy: equal_weight\n",
      "  var_mean: 0.027606401592493057\n",
      "  var_std: 0.0\n",
      "  es_mean: 0.04181969538331032\n",
      "  es_std: 0.0\n",
      "  max_drawback_mean: 0.021213140338659286\n",
      "  max_drawback_std: 0.0\n",
      "  cumulative_pnl_mean: 0.025439638644456863\n",
      "  cumulative_pnl_std: 0.0\n",
      "Strategy: mean_reversion\n",
      "  var_mean: 0.09491269290447235\n",
      "  var_std: 0.0\n",
      "  es_mean: 0.2067442089319229\n",
      "  es_std: 0.0\n",
      "  max_drawback_mean: 0.07910014688968658\n",
      "  max_drawback_std: 0.0\n",
      "  cumulative_pnl_mean: 0.07324480265378952\n",
      "  cumulative_pnl_std: 0.0\n",
      "Strategy: trend_following\n",
      "  var_mean: 0.04603852704167366\n",
      "  var_std: 0.0\n",
      "  es_mean: 0.03988272324204445\n",
      "  es_std: 0.0\n",
      "  max_drawback_mean: 0.033322229981422424\n",
      "  max_drawback_std: 0.0\n",
      "  cumulative_pnl_mean: 0.01928303763270378\n",
      "  cumulative_pnl_std: 0.0\n",
      "Strategy: vol_trading\n",
      "  var_mean: 0.07536911219358444\n",
      "  var_std: 0.0\n",
      "  es_mean: 0.19228506088256836\n",
      "  es_std: 0.0\n",
      "  max_drawback_mean: 0.04561632499098778\n",
      "  max_drawback_std: 0.0\n",
      "  cumulative_pnl_mean: 0.04635878652334213\n",
      "  cumulative_pnl_std: 0.0\n",
      "\n",
      "Mean Metrics across all Strategies:\n",
      "var_mean: 0.06098168343305588\n",
      "es_mean: 0.12018292210996151\n",
      "max_drawback_mean: 0.04481296055018902\n",
      "cumulative_pnl_mean: 0.041081566363573074\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation.strategies import log_return_to_price\n",
    "\n",
    "config_dir = 'src/evaluation/config.yaml'\n",
    "with open(config_dir) as file:\n",
    "    eval_config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "\n",
    "generated_sample = log_return_to_price(generated_sample[:eval_size], cv_val_init_price[:eval_size])\n",
    "cv_val = log_return_to_price(cv_validation_data[:eval_size], cv_val_init_price[:eval_size])\n",
    "\n",
    "# Check if all generated prices are positive\n",
    "all_positive = (generated_sample > 0).all()\n",
    "if not all_positive:\n",
    "    raise ValueError(\"Sanity Check Failed: Some fake prices are not positive.\")\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "res_dict = {\"var_mean\": 0., \"es_mean\": 0., \"max_drawback_mean\": 0., \"cumulative_pnl_mean\": 0.}\n",
    "detailed_res_dict = {}  # Store detailed metrics for each strategy\n",
    "\n",
    "num_strat = 4\n",
    "\n",
    "# Perform final evaluation for each strategy\n",
    "with torch.no_grad():\n",
    "    for strat_name in ['equal_weight', 'mean_reversion', 'trend_following', 'vol_trading']:\n",
    "        # Evaluate strategy\n",
    "        subres_dict = full_evaluation(generated_sample, cv_val, eval_config, strat_name=strat_name)\n",
    "        \n",
    "        # Store detailed results for this strategy\n",
    "        detailed_res_dict[strat_name] = subres_dict\n",
    "        \n",
    "        # Accumulate results for mean calculation\n",
    "        for k in res_dict:\n",
    "            res_dict[k] += subres_dict[k] / num_strat\n",
    "\n",
    "# Print detailed results for each strategy\n",
    "print(\"Detailed Metrics per Strategy:\")\n",
    "for strat_name, metrics in detailed_res_dict.items():\n",
    "    print(f\"Strategy: {strat_name}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "        \n",
    "# Print mean results\n",
    "print(\"\\nMean Metrics across all Strategies:\")\n",
    "for k, v in res_dict.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1600, 24, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_35560\\2633653836.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_log_return = torch.tensor(loaded_array)\n"
     ]
    }
   ],
   "source": [
    "with open(\"./submission_bundle/fake_log_return.pkl\", \"rb\") as f:\n",
    "    loaded_array = pickle.load(f)\n",
    "train_log_return = torch.tensor(loaded_array)\n",
    "print(train_log_return.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1.weight', tensor([[ 0.3909,  0.4226, -0.1121,  0.4545],\n",
      "        [-0.1145,  0.1074, -0.2393,  0.2867],\n",
      "        [ 0.4463, -0.3674,  0.4395,  0.0949],\n",
      "        ...,\n",
      "        [-0.1435, -0.4183,  0.1973,  0.3569],\n",
      "        [ 0.0336, -0.3604, -0.3857, -0.1946],\n",
      "        [ 0.1518,  0.0176,  0.0961,  0.4735]], device='cuda:0')), ('fc1.bias', tensor([ 2.3402e-01,  1.0555e-01, -9.3098e-02,  2.4039e-01,  1.8428e-01,\n",
      "        -4.5362e-01, -2.9256e-01,  2.7816e-02,  1.9459e-01,  2.4066e-01,\n",
      "        -2.9775e-01, -4.9776e-01, -1.4445e-02, -4.7679e-02,  1.4994e-01,\n",
      "        -1.3702e-01,  3.8459e-01,  4.4216e-02,  3.7017e-01, -3.5095e-01,\n",
      "         2.0356e-01,  6.8120e-02, -2.4835e-01,  2.5037e-01, -4.8851e-01,\n",
      "         4.0288e-01,  5.2214e-02,  6.0624e-02,  2.3441e-01,  5.1564e-02,\n",
      "         2.1891e-01,  3.2120e-01, -3.8697e-01,  3.2881e-01, -6.3166e-02,\n",
      "        -1.1265e-01,  1.0487e-01,  3.9200e-01, -2.6849e-01, -3.3395e-01,\n",
      "         3.1463e-01, -2.3712e-01,  1.6613e-01, -6.5126e-02,  1.3577e-01,\n",
      "         3.8454e-01, -2.5007e-01, -2.3793e-01,  2.4745e-01,  3.2891e-02,\n",
      "        -4.5104e-02, -4.4305e-01,  4.2363e-01, -7.0030e-03, -8.7624e-02,\n",
      "        -2.0205e-01, -9.0524e-02,  2.4159e-01,  2.4675e-03,  4.3232e-01,\n",
      "        -1.9319e-02, -6.3279e-02,  2.7894e-01,  1.7929e-03, -9.6516e-02,\n",
      "         1.6964e-01,  3.9791e-01,  1.2876e-01,  3.5302e-01,  3.2658e-01,\n",
      "         1.4365e-01,  1.7970e-01,  1.6443e-01,  5.9519e-02,  4.2965e-01,\n",
      "         4.6127e-01,  1.8350e-01, -1.0973e-02,  4.5009e-01, -3.8843e-01,\n",
      "         3.6660e-01,  2.6949e-01,  3.2086e-01, -2.8892e-02, -3.7030e-01,\n",
      "         3.5940e-01, -2.1358e-01,  1.2823e-01,  2.8502e-01, -4.6488e-01,\n",
      "         4.3968e-02, -1.7529e-01,  3.5714e-01, -3.1566e-01,  3.0527e-01,\n",
      "         3.1370e-01,  2.8068e-01,  4.7653e-01,  8.3071e-02, -4.5150e-01,\n",
      "         3.5843e-01,  5.6620e-02,  2.2834e-02, -4.7689e-01, -1.1318e-01,\n",
      "        -2.4674e-01,  4.9019e-01,  3.6061e-01,  3.7739e-01,  3.4571e-01,\n",
      "        -3.1393e-01, -2.0960e-01, -1.9566e-01, -1.9967e-01,  3.9333e-01,\n",
      "         1.7172e-01,  4.0345e-01, -1.2306e-02, -4.4777e-01, -1.4098e-01,\n",
      "         3.5666e-01,  2.9732e-01,  1.5858e-01, -1.4842e-01, -4.6653e-01,\n",
      "        -2.7170e-01,  2.6558e-01, -1.9965e-01,  2.4405e-01,  1.4305e-01,\n",
      "        -1.9095e-01,  3.0869e-01, -1.5745e-01, -3.7398e-03, -1.8600e-01,\n",
      "        -4.7266e-01,  8.8589e-02,  1.4987e-01, -2.5063e-01,  3.0931e-01,\n",
      "        -4.4622e-01, -4.7916e-01, -3.0870e-01, -1.7279e-01, -4.8847e-02,\n",
      "        -9.4811e-02,  2.3273e-01, -4.4070e-01,  8.1747e-02,  1.5281e-02,\n",
      "         1.3654e-01,  5.0109e-01,  3.1095e-01, -2.7308e-01, -4.0747e-01,\n",
      "        -1.1942e-01, -2.4803e-01,  1.7689e-01,  1.6507e-02,  4.0685e-01,\n",
      "         1.9565e-01, -8.3289e-02,  2.9269e-02,  1.1647e-01, -5.5426e-02,\n",
      "         4.0747e-01, -3.8853e-01,  2.4438e-01, -3.1573e-01, -4.3563e-01,\n",
      "        -9.6317e-02,  2.4573e-01,  3.5805e-01,  1.3098e-01, -3.2661e-02,\n",
      "        -2.8752e-02, -2.0095e-01, -3.5590e-02, -2.6028e-02,  4.3067e-01,\n",
      "         2.9489e-01, -3.9626e-01,  1.6547e-02, -3.0930e-01, -7.3486e-02,\n",
      "        -4.0313e-01,  1.3159e-01, -3.5805e-01,  4.9736e-01,  3.8245e-01,\n",
      "        -3.4241e-01, -4.6841e-01,  3.1107e-02, -1.3578e-01,  1.5107e-01,\n",
      "        -3.3707e-01,  2.0915e-01, -4.3441e-01, -2.6254e-01, -2.6031e-01,\n",
      "         2.4567e-01,  1.2968e-03, -4.7758e-01, -2.8419e-01, -2.2796e-01,\n",
      "        -4.6050e-01,  6.8486e-02,  1.7948e-01, -8.2036e-02, -1.9996e-01,\n",
      "         7.7734e-03, -3.9724e-01, -3.0129e-01, -6.4073e-04,  4.3830e-01,\n",
      "        -1.5633e-01,  2.5206e-01, -1.9349e-01, -1.3371e-01, -4.7335e-01,\n",
      "         4.1237e-01,  4.9070e-01,  1.4680e-03,  3.2069e-01,  4.1228e-01,\n",
      "         2.4761e-01,  2.5949e-01, -4.7348e-01, -4.6886e-01, -3.8213e-01,\n",
      "         1.5595e-01, -4.2933e-01, -3.7871e-01, -2.4028e-01, -4.5878e-01,\n",
      "         1.3505e-02,  8.0119e-02, -2.9127e-01,  3.3084e-01, -1.8517e-01,\n",
      "        -1.3762e-01,  3.8524e-01,  4.3342e-01, -4.8078e-02, -3.5529e-01,\n",
      "        -2.4908e-01,  7.2037e-02,  2.9833e-01,  2.5151e-01, -2.1962e-01,\n",
      "        -4.7206e-01, -4.3931e-01, -1.6215e-01,  1.4529e-02, -2.2095e-01,\n",
      "        -3.9585e-01,  5.9063e-02, -3.9717e-01, -3.8163e-01, -4.0437e-01,\n",
      "        -1.3174e-01,  4.4613e-01,  1.9929e-01, -4.9616e-02,  1.0478e-01,\n",
      "         2.0401e-01,  1.6421e-02, -4.0193e-01, -3.0645e-01, -3.4273e-01,\n",
      "        -4.1835e-04, -4.5744e-01, -8.5221e-02, -1.8001e-01,  4.9431e-01,\n",
      "         4.1125e-01,  2.9438e-01,  3.6430e-02, -1.6278e-01,  1.2920e-01,\n",
      "        -3.4361e-01, -2.1022e-01, -9.2918e-02, -1.1060e-01, -4.7701e-01,\n",
      "         2.0330e-01,  4.1295e-01, -2.7443e-01,  1.4015e-01, -5.1798e-02,\n",
      "        -6.4241e-03,  4.1360e-02,  4.3464e-01,  7.5698e-02, -3.1719e-01,\n",
      "        -1.7808e-01,  2.4787e-01,  1.5677e-01,  1.9350e-02, -5.8548e-02,\n",
      "        -1.9263e-01, -1.7756e-01, -2.6022e-01,  8.9422e-02,  1.4133e-01,\n",
      "         3.8572e-01, -1.0514e-01,  4.4269e-02,  3.2677e-01,  2.2226e-01,\n",
      "         6.7062e-02,  1.5945e-01,  3.4133e-02, -4.2693e-01,  3.1830e-02,\n",
      "        -1.0643e-01,  4.5617e-01,  4.5522e-01,  1.0099e-01,  4.4740e-01,\n",
      "        -2.6164e-01,  4.3926e-01,  4.3441e-01, -4.1344e-03, -3.9933e-01,\n",
      "        -1.6312e-01, -1.2740e-01,  1.5552e-02, -4.5733e-01,  9.8674e-02,\n",
      "        -2.0856e-01, -1.2221e-01, -2.5581e-01, -9.6745e-02, -4.6541e-01,\n",
      "        -2.6375e-01,  5.3774e-02,  3.2522e-01,  4.5894e-01, -3.7730e-01,\n",
      "         2.1473e-01, -2.8225e-01, -3.8994e-01, -8.5597e-03, -2.8301e-01,\n",
      "        -4.2807e-01, -4.6484e-01, -3.3926e-01,  4.1178e-01,  2.8372e-01,\n",
      "        -1.9773e-01, -3.3241e-01, -3.8319e-01, -2.9232e-01, -2.1034e-01,\n",
      "         2.9967e-01,  1.6816e-01, -1.8898e-01,  3.4893e-01, -3.1056e-01,\n",
      "        -4.0666e-01,  1.1411e-01, -2.7887e-01,  1.4485e-01,  4.2648e-01,\n",
      "        -2.3579e-01, -3.4587e-01,  1.9290e-01, -4.5249e-01,  4.5078e-01,\n",
      "        -2.3826e-01,  2.4282e-01, -3.9478e-01, -3.3579e-01,  6.4918e-02,\n",
      "         1.8305e-01,  3.9235e-01,  4.2220e-01, -1.7809e-02, -5.4719e-02,\n",
      "         8.0345e-02, -1.1197e-01,  2.4281e-02, -4.7229e-01, -4.0834e-01,\n",
      "         3.4260e-01, -2.9468e-01,  3.9816e-01,  6.4059e-02,  1.2698e-01,\n",
      "         4.5347e-01, -2.7636e-01, -8.3297e-02,  9.4489e-02,  1.7515e-01,\n",
      "        -4.8974e-01,  1.8267e-01, -2.9592e-01,  7.1192e-02,  3.4179e-01,\n",
      "        -3.9632e-02, -1.1315e-03, -2.7127e-02,  4.2009e-01,  2.8820e-01,\n",
      "         9.0272e-02, -2.9860e-01, -2.7337e-01,  4.0258e-01,  3.6282e-01,\n",
      "         2.9035e-01, -3.9017e-01,  3.9399e-01, -4.3439e-02,  3.6973e-01,\n",
      "         4.3499e-01,  6.3986e-02, -2.0334e-01,  4.7526e-01, -2.6336e-01,\n",
      "         3.2838e-01, -4.8392e-01, -1.5249e-01, -4.3272e-01, -2.2143e-01,\n",
      "         2.1683e-01, -3.5757e-01, -4.3407e-01,  3.6203e-01,  2.6260e-01,\n",
      "         7.7475e-03, -3.5603e-01, -1.3013e-01, -1.6276e-01,  3.1378e-01,\n",
      "        -1.6631e-01, -1.3849e-01, -3.5149e-01, -2.3377e-01,  2.7497e-01,\n",
      "         3.2688e-01,  7.8140e-02, -1.8416e-01,  4.8542e-01,  1.0476e-01,\n",
      "        -1.8802e-01, -1.7253e-01, -6.1521e-02,  2.4211e-01,  1.8585e-01,\n",
      "         3.6711e-01, -1.1697e-02,  4.1654e-01, -1.9886e-01, -2.2748e-01,\n",
      "        -1.8047e-01, -4.6758e-01, -3.2628e-01, -4.5120e-01, -2.1628e-02,\n",
      "         1.5187e-02, -1.2360e-01, -3.4037e-01,  4.4907e-01, -1.6077e-01,\n",
      "         2.4285e-01,  3.4847e-01, -3.2485e-01, -5.4790e-02,  2.9190e-01,\n",
      "         4.8867e-01, -5.7651e-02,  3.6759e-01, -3.9013e-01, -3.2287e-01,\n",
      "         4.1618e-01, -3.6532e-02,  4.9885e-01,  4.0155e-02, -2.0689e-01,\n",
      "         4.7655e-01,  4.4233e-01,  5.6574e-02, -2.9957e-01, -9.2036e-03,\n",
      "        -2.4096e-01,  3.6672e-01,  3.3930e-02,  1.1006e-01,  3.0417e-01,\n",
      "         1.6051e-01, -3.1452e-01,  4.1497e-01,  3.1206e-01, -3.0943e-01,\n",
      "         3.8017e-01,  1.4565e-01, -1.0261e-01, -3.5422e-01, -7.5398e-02,\n",
      "        -4.8842e-01,  2.8988e-01,  3.6334e-01, -1.3887e-01,  4.6650e-01,\n",
      "        -1.8185e-01,  9.1723e-02, -3.4804e-01, -1.0554e-02,  2.0509e-01,\n",
      "         2.2006e-01, -5.4082e-03], device='cuda:0')), ('fc2.weight', tensor([[-0.0312,  0.0362,  0.0243,  ...,  0.0252, -0.0216,  0.0161],\n",
      "        [-0.0122,  0.0028, -0.0126,  ..., -0.0399,  0.0254,  0.0431],\n",
      "        [-0.0353, -0.0045, -0.0335,  ...,  0.0136, -0.0284, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0336,  0.0127, -0.0028,  ..., -0.0440,  0.0329,  0.0222],\n",
      "        [-0.0200,  0.0383, -0.0137,  ..., -0.0048,  0.0087,  0.0122],\n",
      "        [-0.0230, -0.0294,  0.0069,  ..., -0.0397,  0.0109, -0.0329]],\n",
      "       device='cuda:0')), ('fc2.bias', tensor([-1.0404e-02, -9.4759e-03, -1.8898e-02,  4.2623e-02,  8.7078e-03,\n",
      "        -6.5087e-03,  2.2228e-02, -1.5126e-02, -2.6708e-02, -1.8826e-03,\n",
      "        -1.5490e-02,  1.9290e-02, -3.3618e-02,  3.5730e-02,  1.5186e-02,\n",
      "        -3.6534e-02, -2.9050e-02,  2.4587e-03, -2.2085e-02,  3.8752e-02,\n",
      "        -1.1991e-02, -3.5882e-02,  3.1730e-02, -5.3142e-04,  1.3236e-03,\n",
      "        -2.2973e-02,  3.6367e-02, -7.1873e-03, -3.4423e-02, -2.1236e-02,\n",
      "        -8.4220e-03, -2.2263e-02, -2.9283e-02, -1.3282e-02, -4.9934e-03,\n",
      "         4.0605e-02, -3.2511e-02, -7.3735e-03, -2.6534e-04,  2.7683e-02,\n",
      "         2.4019e-02,  3.2976e-03,  2.8189e-02, -1.6988e-02, -4.5819e-02,\n",
      "         4.6560e-02,  1.9731e-02,  1.0175e-02, -2.2494e-02,  2.4515e-03,\n",
      "         3.4816e-02,  6.1191e-03,  4.0013e-02, -4.2614e-02,  4.1697e-02,\n",
      "         5.6594e-04, -2.5444e-02,  3.2144e-02, -3.2799e-02, -3.0654e-02,\n",
      "         2.7994e-02,  3.7739e-02,  6.4835e-03, -2.8290e-02, -2.0371e-02,\n",
      "        -4.2339e-03,  3.3035e-03,  5.6274e-04, -2.6181e-03,  3.3245e-02,\n",
      "         4.1070e-02,  3.7371e-02,  1.2856e-02,  3.1135e-02,  3.1021e-02,\n",
      "        -2.1013e-02,  4.3079e-02,  4.1684e-02, -4.2587e-03,  3.3387e-02,\n",
      "         1.7682e-02,  8.5235e-05,  3.9078e-03,  2.1502e-02, -1.3899e-02,\n",
      "         3.8429e-02, -2.9975e-03,  3.6965e-02, -3.8193e-03,  3.4066e-02,\n",
      "        -9.0051e-03,  4.5774e-02, -3.1444e-02, -6.9748e-03,  1.0843e-02,\n",
      "         2.7509e-02,  3.3029e-03,  5.1756e-03, -2.5556e-02, -3.6909e-02,\n",
      "        -2.6378e-02, -1.1244e-02,  2.0136e-02,  4.0623e-02, -3.8335e-02,\n",
      "        -1.1746e-02,  2.7696e-02, -2.4120e-03, -1.3275e-02,  2.8651e-02,\n",
      "        -1.7028e-02,  8.9033e-03, -6.2469e-03,  3.8607e-02, -2.9933e-02,\n",
      "         1.9771e-02,  1.3546e-03,  2.3020e-02,  4.3162e-02,  3.9934e-02,\n",
      "         1.4913e-02,  3.7036e-02, -3.5080e-02,  4.3750e-02, -3.3069e-02,\n",
      "         2.5550e-03, -1.0668e-03, -3.3602e-02, -1.6261e-02,  7.6004e-03,\n",
      "         3.5159e-02, -2.9511e-02, -1.3123e-02, -7.5986e-03,  2.1383e-02,\n",
      "        -1.7728e-02,  4.4510e-02,  4.4953e-03,  1.0301e-02,  1.2034e-02,\n",
      "        -2.0461e-02, -3.2274e-02, -1.9558e-02,  2.1981e-02,  1.8192e-02,\n",
      "        -1.9730e-02, -3.7645e-02,  2.6731e-02, -7.5099e-03,  3.6897e-02,\n",
      "        -2.1392e-02, -4.0020e-03, -3.0798e-02,  3.7894e-02, -2.3824e-02,\n",
      "        -7.8486e-03,  2.0375e-02,  2.9990e-02,  4.4208e-02,  3.7790e-02,\n",
      "        -2.4951e-02,  3.8632e-02, -4.1544e-02,  3.1538e-02, -2.1540e-02,\n",
      "         1.0601e-02,  3.9298e-02,  7.0462e-03, -2.5017e-02,  3.4285e-03,\n",
      "        -3.9958e-02,  1.0627e-02,  9.1122e-03, -1.7374e-02, -4.0854e-02,\n",
      "        -1.0537e-02, -1.7590e-02,  3.8280e-02,  4.2044e-02, -3.2561e-02,\n",
      "         2.3530e-02, -1.5468e-02,  9.4996e-03, -1.9440e-02, -1.7969e-02,\n",
      "         4.1102e-02, -2.7327e-02,  4.7366e-02, -2.6184e-02,  3.7425e-02,\n",
      "        -1.5434e-02, -1.2627e-02,  9.0903e-03,  1.2897e-02, -2.1799e-02,\n",
      "        -3.8384e-02, -2.7084e-02, -7.3718e-03,  3.1421e-03, -1.6641e-02,\n",
      "        -1.1956e-02,  3.3917e-02, -3.1718e-02,  4.4838e-02, -3.4970e-02,\n",
      "        -3.0472e-02, -3.8675e-02,  3.9990e-02, -3.2356e-03, -3.6788e-02,\n",
      "        -1.3022e-02,  4.1393e-02,  4.5294e-02, -3.3551e-02, -7.7361e-03,\n",
      "         4.6754e-02, -3.9783e-02, -3.0382e-02, -9.1159e-03,  1.6036e-02,\n",
      "         4.7980e-02, -2.4492e-02, -2.1137e-02,  3.1715e-02,  2.9227e-02,\n",
      "         2.6208e-02, -5.3250e-03, -3.6655e-02,  6.6298e-03, -2.9876e-02,\n",
      "        -2.8257e-02,  6.1394e-03,  2.0867e-02, -3.7233e-02,  1.9537e-02,\n",
      "         2.3292e-02,  4.7525e-02,  4.7981e-03, -2.0921e-02, -2.6090e-02,\n",
      "         2.1472e-02,  2.8206e-02,  3.3705e-02,  4.4434e-02,  9.8359e-03,\n",
      "        -3.5960e-02, -3.3179e-02, -1.9974e-03,  1.8762e-02, -3.3880e-02,\n",
      "         2.7257e-02, -6.8899e-03, -8.0771e-03, -5.0949e-03,  3.0672e-02,\n",
      "         7.6214e-04,  3.9395e-02,  2.6885e-02, -4.2095e-02,  3.0704e-02,\n",
      "        -2.1117e-02, -4.9440e-03, -6.0720e-03, -8.8806e-03,  1.0837e-02,\n",
      "         3.7682e-02, -8.9726e-03,  4.5816e-02, -4.1091e-02, -1.0541e-02,\n",
      "        -3.8429e-02, -2.5927e-02,  6.9492e-03,  1.7019e-02, -3.2269e-02,\n",
      "         1.4841e-02, -4.8759e-03, -3.4503e-02, -2.3593e-02, -5.1536e-03,\n",
      "        -1.3119e-02, -3.3991e-02, -3.2748e-03, -3.4543e-02, -1.6357e-02,\n",
      "        -7.4643e-03, -3.0886e-02, -7.0073e-03,  4.7664e-02,  2.7425e-02,\n",
      "         1.1029e-02,  1.2159e-02, -1.2629e-02,  1.0718e-03,  3.6494e-02,\n",
      "        -2.2811e-02,  2.2381e-02,  3.7128e-02, -3.9697e-02,  4.1736e-03,\n",
      "        -1.6767e-02, -9.3073e-03,  1.7001e-02,  4.2392e-02,  1.0327e-02,\n",
      "        -9.2362e-03, -9.0749e-03, -4.9962e-03,  2.7428e-02, -3.2576e-02,\n",
      "         3.6118e-02,  1.5361e-02,  6.8550e-03, -1.6682e-02, -4.2924e-02,\n",
      "         3.5100e-02, -2.1531e-02,  2.9513e-02,  4.4156e-02,  2.5902e-02,\n",
      "        -1.5193e-02,  2.3453e-02, -1.9613e-02,  1.8985e-02, -2.8014e-02,\n",
      "        -1.1341e-02, -3.0007e-02,  3.2603e-02,  3.6768e-02, -3.3984e-02,\n",
      "        -2.4265e-02, -1.6615e-02, -4.8496e-04,  3.4629e-02, -3.2122e-02,\n",
      "         1.6051e-02, -2.9989e-02,  4.1919e-03,  2.8996e-02,  1.0653e-02,\n",
      "         7.4113e-03,  6.7151e-03, -2.6257e-02,  3.8994e-03,  8.7124e-03,\n",
      "        -1.0566e-02,  1.7138e-04, -3.6444e-02,  1.7596e-03, -9.7656e-03,\n",
      "        -7.5941e-03, -2.6272e-02,  4.1467e-02,  2.9737e-02, -1.1730e-02,\n",
      "        -3.3992e-02,  4.6195e-02,  3.0364e-02,  4.0141e-02,  2.0109e-03,\n",
      "         2.8354e-02,  2.6791e-02, -2.7625e-02, -1.1457e-02, -1.7815e-02,\n",
      "        -1.0157e-02,  5.8367e-03,  3.5831e-02, -3.6628e-02,  1.1307e-02,\n",
      "         1.1464e-02,  8.3306e-03, -1.7622e-02,  2.9825e-02,  2.8317e-02,\n",
      "         3.1125e-02,  2.3904e-02,  4.3882e-02,  7.8843e-03, -2.5427e-02,\n",
      "         1.1990e-02,  1.4566e-02, -2.8470e-02,  2.3758e-02,  1.3614e-02,\n",
      "         5.1299e-04,  2.8808e-02,  1.8834e-02, -3.8975e-02, -3.5798e-02,\n",
      "        -2.0730e-02,  1.0498e-02, -1.0676e-02, -6.9267e-03,  1.3519e-03,\n",
      "         1.6862e-02,  4.9464e-02,  2.6196e-02, -1.2121e-02,  1.8911e-02,\n",
      "         2.4541e-02, -1.5067e-02, -2.4446e-02,  1.7677e-02, -1.6478e-02,\n",
      "         3.9607e-02,  4.4172e-02,  2.7996e-02, -3.0928e-02, -9.3528e-03,\n",
      "         2.6460e-02, -3.6238e-02, -2.1913e-02, -1.1650e-02,  1.0115e-02,\n",
      "        -1.4648e-02,  3.1095e-02,  4.6463e-02,  5.0055e-03, -2.2752e-03,\n",
      "         1.6263e-02, -2.2095e-02, -2.3666e-02, -2.1926e-02, -1.6983e-02,\n",
      "         2.7073e-02,  1.7538e-02,  1.1479e-02,  2.5363e-02, -1.0908e-02,\n",
      "        -3.6368e-02,  1.2847e-02, -2.3282e-02, -2.3837e-02, -1.8502e-02,\n",
      "         4.2631e-02,  8.1762e-03, -1.0317e-02,  3.9411e-02,  3.5543e-02,\n",
      "        -4.1237e-02, -2.0496e-02,  4.3576e-02, -3.2691e-02, -1.5621e-02,\n",
      "        -4.4300e-03,  2.5029e-02,  4.1584e-02,  3.1503e-02, -7.0781e-04,\n",
      "         2.8127e-02,  5.9843e-03,  4.3890e-02,  3.6319e-02, -1.4386e-02,\n",
      "        -3.7095e-02,  1.1816e-02,  5.7395e-03,  5.3161e-03,  1.2618e-02,\n",
      "         4.2026e-02,  1.2092e-02, -2.0985e-02,  4.6541e-02,  2.0341e-02,\n",
      "         2.4278e-02, -1.6792e-02, -8.5536e-03,  1.5066e-02,  2.8357e-02,\n",
      "         2.1105e-02, -3.4552e-02,  2.8361e-02, -1.9994e-02,  4.4179e-03,\n",
      "         1.1933e-03, -3.9221e-02,  3.2550e-02, -7.9680e-03,  3.6870e-02,\n",
      "         3.7027e-02, -2.0555e-02, -3.4091e-02,  2.2849e-02,  4.5342e-02,\n",
      "         1.6604e-03, -3.0979e-02,  2.8676e-02,  7.5576e-03,  1.6968e-02,\n",
      "        -2.5782e-02,  3.0626e-02, -2.7540e-02, -3.1655e-02,  2.9374e-02,\n",
      "         5.2085e-04,  1.8278e-02,  3.7040e-04, -3.2102e-02, -2.6353e-02,\n",
      "        -1.7584e-02,  2.1494e-02, -1.4566e-02, -2.6874e-02, -2.7804e-02,\n",
      "        -3.4428e-02,  1.8762e-02,  3.6075e-02, -1.5726e-02,  4.7478e-02,\n",
      "         2.3045e-02, -4.1900e-04], device='cuda:0')), ('fc3.weight', tensor([[ 0.0422, -0.0175,  0.0391,  ..., -0.0103,  0.0243,  0.0095],\n",
      "        [-0.0067,  0.0409, -0.0292,  ...,  0.0023, -0.0387, -0.0071],\n",
      "        [-0.0349,  0.0145,  0.0203,  ..., -0.0068,  0.0300,  0.0147],\n",
      "        ...,\n",
      "        [ 0.0454, -0.0107,  0.0099,  ..., -0.0043, -0.0100,  0.0145],\n",
      "        [ 0.0073, -0.0423,  0.0241,  ...,  0.0235, -0.0262, -0.0442],\n",
      "        [ 0.0106,  0.0301,  0.0239,  ...,  0.0194, -0.0074,  0.0010]],\n",
      "       device='cuda:0')), ('fc3.bias', tensor([ 3.0585e-02, -4.3489e-03,  3.8486e-02, -2.8948e-02, -1.6118e-02,\n",
      "         3.3683e-02,  1.8774e-02,  3.9943e-02,  2.5661e-02,  2.1387e-02,\n",
      "        -3.5908e-02, -1.5664e-02, -2.1951e-02, -6.9462e-03,  1.1299e-02,\n",
      "        -3.0783e-02,  3.0834e-02, -2.6831e-02,  7.4862e-03,  1.6240e-03,\n",
      "         2.5874e-02, -8.5224e-03, -1.1984e-02, -3.5931e-02, -2.4194e-02,\n",
      "        -3.5420e-02,  3.9844e-02,  2.7900e-02,  4.7027e-02, -1.2047e-02,\n",
      "         1.3570e-02,  2.1691e-02, -1.6456e-02, -2.6956e-02,  4.9424e-03,\n",
      "        -3.8494e-02, -1.6604e-02, -4.3702e-02, -4.9555e-03, -4.4762e-03,\n",
      "        -1.5647e-02,  1.3755e-02,  1.5127e-02,  1.7063e-02, -3.4028e-02,\n",
      "         8.3854e-03,  3.0471e-02,  9.6609e-03, -1.3739e-02,  3.2614e-02,\n",
      "        -1.9269e-02, -3.1131e-02, -3.9847e-02, -2.9720e-02, -2.0392e-02,\n",
      "        -2.3582e-02,  4.0280e-02,  4.2513e-02,  1.2474e-02,  3.3257e-02,\n",
      "         2.6888e-02,  2.6761e-02,  1.3112e-02,  7.7304e-03,  2.4601e-02,\n",
      "        -2.4184e-02,  2.8732e-02, -3.3661e-02, -2.3729e-02,  1.5015e-02,\n",
      "         1.5644e-02, -3.5403e-02,  4.3188e-02,  1.9475e-03,  1.4685e-02,\n",
      "        -3.9514e-02,  4.7391e-02,  1.0802e-02, -1.1914e-02,  5.6373e-03,\n",
      "        -3.7628e-02,  1.7162e-03,  2.7298e-02, -8.5798e-03,  3.3518e-02,\n",
      "         3.9222e-02,  1.6848e-03,  2.0615e-02, -2.3084e-03,  2.7639e-02,\n",
      "         6.7272e-03, -2.4076e-02, -4.3849e-02,  3.9043e-02,  2.3527e-02,\n",
      "        -1.0292e-02, -1.1875e-02,  2.6375e-02,  3.9913e-02,  3.5493e-02,\n",
      "         1.7449e-02, -2.4231e-02, -1.1153e-02,  3.4212e-02, -6.3297e-03,\n",
      "        -2.2253e-02,  1.9564e-02, -2.7414e-02,  4.4086e-02,  1.6680e-02,\n",
      "        -3.0866e-02,  1.2750e-02,  1.2423e-02, -2.6651e-03,  4.4156e-02,\n",
      "        -5.5766e-03,  8.5816e-03, -3.8165e-02,  4.5317e-02, -2.9123e-02,\n",
      "         1.4609e-02,  2.3843e-02, -8.2645e-03,  9.9222e-03,  3.9976e-02,\n",
      "         2.9642e-02,  3.4365e-03,  9.0179e-03,  4.9762e-03,  9.6080e-03,\n",
      "        -1.0012e-02,  1.6175e-02, -8.4870e-04,  1.5249e-02,  2.7499e-02,\n",
      "        -4.2922e-02,  7.2806e-03,  2.1533e-02,  5.9143e-03,  2.1965e-02,\n",
      "        -3.1028e-02,  8.2202e-03,  3.5953e-02,  2.0096e-02, -3.4597e-02,\n",
      "        -2.2343e-02,  4.1851e-02, -8.3729e-03, -3.7292e-02, -2.3108e-02,\n",
      "        -2.8321e-02, -2.3027e-02, -5.8545e-03, -5.0500e-03,  3.0253e-02,\n",
      "         4.6844e-02,  7.9794e-03,  3.9762e-02,  1.2723e-02, -4.1835e-02,\n",
      "        -3.7433e-02,  3.0113e-02, -3.0937e-02,  3.1902e-02,  2.8053e-02,\n",
      "        -3.0132e-02, -2.1577e-02,  4.8183e-02, -2.6760e-02,  4.7194e-02,\n",
      "        -3.7331e-02,  2.9377e-02, -3.5301e-02, -3.7839e-02,  3.4684e-02,\n",
      "        -5.6741e-03, -3.7328e-02,  1.1007e-02,  1.6309e-02,  3.8575e-02,\n",
      "        -1.6359e-02, -3.3059e-02, -2.5695e-02,  7.0116e-03, -1.4526e-02,\n",
      "         3.4815e-02,  6.8494e-04,  1.4868e-02, -2.3592e-03, -2.1746e-02,\n",
      "         3.0357e-02, -3.8461e-02, -1.9909e-02,  1.8813e-02,  2.2043e-02,\n",
      "         4.8257e-02, -3.7347e-02,  1.0939e-02,  9.7801e-04, -1.2964e-02,\n",
      "         4.5247e-02,  3.0883e-02, -1.9979e-02,  3.3427e-02,  2.5631e-02,\n",
      "         6.8991e-05,  3.5550e-02, -3.4464e-02,  4.5722e-02, -1.6792e-02,\n",
      "         4.4535e-02, -2.8390e-02,  9.2829e-03, -1.1844e-02,  3.7693e-02,\n",
      "        -1.9306e-02, -2.3778e-02, -5.8941e-04,  3.4398e-02,  3.9296e-02,\n",
      "         2.6367e-02,  2.6388e-02, -5.3485e-03, -2.0508e-02,  3.3721e-02,\n",
      "        -1.8452e-02, -3.3463e-02,  5.0928e-03,  2.6242e-03, -5.9161e-03,\n",
      "         2.7858e-02, -1.2405e-02, -1.6716e-02, -3.3588e-02, -3.1476e-02,\n",
      "         2.6680e-02,  1.0523e-02,  3.8444e-02,  4.1738e-02, -2.8196e-02,\n",
      "        -3.0315e-02,  2.6184e-02,  4.4918e-02,  3.7039e-02, -1.3599e-02,\n",
      "        -2.2590e-04,  2.1341e-02, -1.4475e-02,  1.0709e-02, -4.0204e-02,\n",
      "         3.2103e-02, -3.5438e-02,  7.8642e-03, -1.9110e-02,  1.9829e-02,\n",
      "        -3.4342e-02, -2.6179e-02,  4.0432e-02,  4.3999e-02, -1.5633e-02,\n",
      "         3.7485e-02, -2.5985e-02, -3.7462e-02,  1.3880e-02,  4.1438e-03,\n",
      "         1.3233e-02,  2.6582e-02, -1.8722e-02,  2.6085e-02,  2.2998e-02,\n",
      "        -2.4807e-02, -2.1469e-02,  1.3553e-02,  3.5066e-02,  3.9575e-02,\n",
      "        -1.2879e-02,  1.1399e-02, -3.7430e-02,  2.9042e-02, -3.2319e-02,\n",
      "         6.4027e-03, -2.9516e-02,  3.2540e-02, -2.0160e-03,  3.8534e-03,\n",
      "         3.0809e-03, -4.3518e-02, -1.7684e-02,  7.9118e-03,  4.3031e-02,\n",
      "        -1.6533e-02,  9.8385e-03, -1.5660e-02, -2.5628e-02, -6.6737e-03,\n",
      "         2.0971e-02, -3.1253e-02,  4.1082e-02,  6.8578e-03, -2.3292e-02,\n",
      "         4.8460e-02, -1.9194e-02, -2.3013e-02,  4.9170e-02,  2.9064e-02,\n",
      "         4.1997e-02, -5.2887e-03, -4.1939e-02,  3.2411e-02, -4.2706e-02,\n",
      "         2.3220e-02, -4.0263e-02,  1.6205e-02, -2.1526e-02,  4.3541e-02,\n",
      "         1.8741e-02,  7.4016e-03, -2.6264e-02,  2.7921e-02, -3.2647e-02,\n",
      "         3.0946e-02,  4.5195e-03, -3.0074e-02,  2.5563e-02,  6.4589e-03,\n",
      "        -3.5004e-02, -5.3754e-03, -2.2879e-02, -2.8056e-02, -1.6367e-02,\n",
      "        -7.8488e-03,  1.6559e-02,  6.2979e-03, -2.0174e-02, -2.7339e-02,\n",
      "        -3.1349e-02, -3.4626e-02, -2.4641e-02,  1.8215e-02, -1.9046e-02,\n",
      "         2.1804e-02, -1.8872e-02,  2.8584e-02,  2.3646e-02,  2.5271e-02,\n",
      "         6.5137e-03,  1.8288e-02,  4.7311e-02,  2.9868e-02, -2.0382e-02,\n",
      "        -1.7803e-02, -4.0294e-02,  1.0144e-02, -4.0370e-02,  1.2109e-03,\n",
      "        -1.5977e-02,  2.0979e-02, -4.0877e-04,  2.5450e-02,  1.0506e-02,\n",
      "        -2.2335e-02, -2.1589e-02,  3.8355e-02,  2.5402e-02,  3.4410e-02,\n",
      "        -7.2039e-03, -2.1372e-02,  7.0944e-03, -3.8464e-02, -8.6849e-03,\n",
      "        -2.0052e-02,  8.0982e-03,  6.1297e-03, -1.3040e-02, -2.8136e-02,\n",
      "         4.2476e-02,  3.6241e-02,  6.8027e-03, -1.4534e-02, -3.4007e-02,\n",
      "         1.3690e-02,  2.8356e-02, -9.8868e-03, -1.0651e-02,  4.4571e-02,\n",
      "        -3.8768e-02,  1.2502e-02,  1.8786e-02,  2.7583e-03,  1.3214e-02,\n",
      "         1.4925e-02,  2.2885e-02,  2.1304e-02, -6.6482e-03, -1.7766e-02,\n",
      "         5.3032e-03, -2.0568e-03,  7.3768e-04, -3.3773e-02, -8.5245e-03,\n",
      "         7.2563e-03,  8.8469e-03,  1.5035e-02,  2.3979e-02, -3.8711e-02,\n",
      "        -2.9003e-04,  4.7846e-02, -1.5661e-04, -1.6564e-02,  1.0825e-02,\n",
      "         1.2100e-02,  4.5570e-02, -1.3940e-02, -6.4415e-03, -2.9228e-02,\n",
      "        -1.4925e-03,  2.0500e-02, -1.4363e-02, -5.7324e-03, -2.4100e-02,\n",
      "         4.6557e-02, -1.4742e-02,  1.7992e-02,  1.7358e-02,  3.1276e-02,\n",
      "         6.2654e-03,  9.4741e-03, -3.0017e-02,  1.5136e-02, -3.7994e-02,\n",
      "        -1.0731e-02, -2.5038e-02, -2.2004e-02,  3.5001e-02,  4.7375e-02,\n",
      "         8.6357e-03, -2.5788e-02,  8.7818e-04, -3.9268e-02,  1.8517e-02,\n",
      "        -3.3180e-02, -3.7107e-03, -4.0677e-02, -1.9607e-02,  1.0842e-02,\n",
      "         3.2325e-02,  1.9956e-02, -1.3336e-03,  1.8497e-02, -7.9473e-03,\n",
      "         8.8849e-03,  3.6114e-02, -3.7172e-02, -1.4219e-02, -3.3089e-02,\n",
      "         2.9289e-02,  2.6692e-02,  4.1478e-02,  3.5155e-02,  6.1620e-03,\n",
      "         3.8462e-02,  4.7742e-02, -3.4914e-02, -3.1771e-02,  8.4541e-03,\n",
      "        -5.4652e-03, -1.5486e-02, -3.0481e-02,  9.5546e-03, -3.9478e-02,\n",
      "        -4.3256e-02, -6.5799e-03, -3.8012e-02, -4.2594e-02, -7.0453e-03,\n",
      "         6.6380e-03,  4.4695e-02, -3.7935e-03,  1.1571e-02,  3.0827e-02,\n",
      "        -1.9417e-02,  3.6712e-02, -4.6235e-02,  3.9074e-02,  3.5848e-03,\n",
      "         4.2880e-02,  1.9111e-02,  4.3049e-02,  2.0199e-02,  2.3448e-02,\n",
      "         1.5657e-02,  1.2315e-02, -2.7951e-02,  1.6593e-02,  8.3254e-03,\n",
      "         1.2315e-02, -4.2681e-03, -2.2359e-02, -1.4238e-02, -2.4608e-02,\n",
      "        -3.7955e-02, -1.4062e-02,  4.4314e-03, -1.8114e-02,  2.9016e-02,\n",
      "         4.1057e-02, -1.2759e-02, -1.1217e-02, -3.3647e-02, -1.0996e-03,\n",
      "        -3.5210e-02,  3.8965e-02], device='cuda:0')), ('fc4.weight', tensor([[-0.0323,  0.0156, -0.0434,  ..., -0.0416, -0.0011, -0.0056],\n",
      "        [-0.0087, -0.0384, -0.0306,  ..., -0.0393,  0.0345,  0.0143],\n",
      "        [-0.0026, -0.0121,  0.0326,  ...,  0.0226, -0.0488,  0.0329]],\n",
      "       device='cuda:0')), ('fc4.bias', tensor([ 0.0375,  0.0229, -0.0038], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "with open(\"./submission_bundle/model_dict.pkl\", \"rb\") as f:\n",
    "    loaded_array = pickle.load(f)\n",
    "print(loaded_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
